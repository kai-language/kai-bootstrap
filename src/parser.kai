#import "lexer.kai" lex
#import "alloc.kai"
#import "ast.kai" _
#import "errors.kai"
#import "strings.kai"

#import builtin("types") _

#import "libc.kai"

LowestPrecedence  :: 0
UnaryPrecedence   :: 7
HighestPrecedence :: 8

DefaultListLen :: 10

SourceFile :: struct {
    arena: alloc.Arena
    fullpath: string
    lexer: lex.Lexer
    tokens: []lex.Token
    tokenIndex: u64
    currentToken: lex.Token
}

SourcePackage :: struct {
    initPath: string
    files: []*SourceFile
    totalLineCount: u64
}

SourceFileInit :: fn(file: *SourceFile, path: string) -> bool {
    lexer: lex.Lexer
    ok := lex.LexerInit(&lexer, path)
    if !ok
        return false

    allocator := alloc.DefaultAllocatorInit()
    alloc.ArrayInit(allocator, &file.tokens, lexer.data.len)

    for true {
        tok := lex.NextToken(&lexer)
        alloc.Append(allocator, &file.tokens, tok)

        libc.printf("token: \x1b[35m%s\x1b[0m, lit: \x1b[34m\"%.*s\"\x1b[0m\n".raw, lex.Describe(tok).raw, tok.lit.len, tok.lit.raw)

        if tok.kind == lex.TokenKind.Eof
            break
    }

    file.fullpath = path
    alloc.ArenaInit(&file.arena, SizeOf(Ast) * lexer.data.len)

    // load the first token
    next(file)

    return true
}

MakeNode :: fn(f: *SourceFile, ast: Ast) -> *Ast {
    using alloc
    arena := &f.arena
    node := cast(*Ast)Alloc(ArenaAllocatorInit(arena), SizeOf(Ast))
    <node = ast
    return node
}

MakeBadExpr :: fn(f: *SourceFile, begin, end: lex.Token) -> *Ast {
    return MakeNode(f, Ast { BadExpr: { begin, end } })
}

MakeNilLiteral :: fn(f: *SourceFile, token: lex.Token) -> *Ast {
    return MakeNode(f, Ast { NilLiteral: token })
}

MakeIdent :: fn(f: *SourceFile, token: lex.Token) -> *Ast {
    return MakeNode(f, Ast { Ident: token })
}

MakeEllipsis :: fn(f: *SourceFile, expr: *Ast, token: lex.Token) -> *Ast {
    return MakeNode(f, Ast { Ellipsis: { expr: expr, token: token } })
}

MakeBasicLit :: fn(f: *SourceFile, token: lex.Token) -> *Ast {
    return MakeNode(f, Ast { BasicLit: token })
}

MakeIdentList :: fn(f: *SourceFile, token: lex.Token, idents: []*Ast) -> *Ast {
    return MakeNode(f, Ast { IdentList: { token: token, idents: idents } })
}

MakeFuncLit :: fn(f: *SourceFile, token: lex.Token, type, body: *Ast) -> *Ast {
    return MakeNode(f, Ast { FuncLit: { token: token, type: type, body: body } })
}

MakeCompositeLit :: fn(f: *SourceFile, begin, end: lex.Token, elements: []*Ast) -> *Ast {
    return MakeNode(f, Ast { CompositeLit: { begin: begin, end: end, elements: elements } })
}

MakeParen :: fn(f: *SourceFile, begin, end: lex.Token, expr: *Ast) -> *Ast {
    return MakeNode(f, Ast { Paren: { begin: begin, end: end, expr: expr } })
}

MakeSelector :: fn(f: *SourceFile, token: lex.Token, rec, sel: *Ast) -> *Ast {
    return MakeNode(f, Ast { Selector: { token: token, rec: rec, sel: sel } })
}

MakeSubscript :: fn(f: *SourceFile, begin, end: lex.Token, rec, index: *Ast) -> *Ast {
    return MakeNode(f, Ast { Subscript: { begin: begin, end: end, rec: rec, index: index } })
}

MakeSlice :: fn(f: *SourceFile, begin, end: lex.Token, expr, hi, lo: *Ast) -> *Ast {
    return MakeNode(f, Ast { Slice: { begin: begin, end: end, expr: expr, hi: hi, lo: lo } })
}

MakeAutocast :: fn(f: *SourceFile, token: lex.Token, expr: *Ast) -> *Ast {
    return MakeNode(f, Ast { Autocast: { token: token, expr: expr } })
}

MakeCast :: fn(f: *SourceFile, kind: lex.Token, type, expr: *Ast) -> *Ast {
    return MakeNode(f, Ast { Cast: { kind: kind, type: type, expr: expr } })
}

MakeCall :: fn(f: *SourceFile, begin, end: lex.Token, labels, args: []*Ast) -> *Ast {
    return MakeNode(f, Ast { Call: { begin: begin, end: end, labels: labels, args: args } })
}

MakeUnary :: fn(f: *SourceFile, op: lex.Token, element: *Ast) -> *Ast {
    return MakeNode(f, Ast { Unary: { op: op, kind: tokenOperator(op), element: element } })
}

MakeBinary :: fn(f: *SourceFile, op: lex.Token, lhs, rhs: *Ast) -> *Ast {
    return MakeNode(f, Ast { Binary: { op: op, kind: tokenOperator(op), lhs: lhs, rhs: rhs } })
}

MakeTernary :: fn(f: *SourceFile, qmark, colon: lex.Token, cond, then, els: *Ast) -> *Ast {
    return MakeNode(f, Ast { Ternary: { qmark: qmark, colon: colon, cond: cond, then: then, els: els } })
}

MakeKeyValue :: fn(f: *SourceFile, token: lex.Token, key, value: *Ast) -> *Ast {
    return MakeNode(f, Ast { KeyValue: { token: token, key: key, value: value } })
}

MakePointerType :: fn(f: *SourceFile, token: lex.Token, type: *Ast) -> *Ast {
    return MakeNode(f, Ast { PointerType: { token: token, type: type } })
}

MakeArrayType :: fn(f: *SourceFile, begin, end: lex.Token, length, type: *Ast) -> *Ast {
    return MakeNode(f, Ast { ArrayType: { begin: begin, end: end, length: length, type: type } })
}

MakeSliceType :: fn(f: *SourceFile, begin, end: lex.Token, type: *Ast) -> *Ast {
    return MakeNode(f, Ast { SliceType: { begin: begin, end: end, type: type } })
}

MakeVectorType :: fn(f: *SourceFile, begin, end: lex.Token, size, type: *Ast) -> *Ast {
    return MakeNode(f, Ast { VectorType: { begin: begin, end: end, size: size, type: type } })
}

MakePolyType :: fn(f: *SourceFile, token: lex.Token, type: *Ast) -> *Ast {
    return MakeNode(f, Ast { PolyType: { token: token, type: type } })
}

MakeVariadicType :: fn(f: *SourceFile, token: lex.Token, type: *Ast, isCVargs: bool) -> *Ast {
    return MakeNode(f, Ast { VariadicType: { token: token, type: type, isCVargs: isCVargs } })
}

MakeBadStmt :: fn(f: *SourceFile, begin, end: lex.Token) -> *Ast {
    return MakeNode(f, Ast { BadStmt: { begin: begin, end: end } })
}

MakeEmpty :: fn(f: *SourceFile, token: lex.Token) -> *Ast {
    return MakeNode(f, Ast { Empty: token })
}

MakeLabel :: fn(f: *SourceFile, token: lex.Token) -> *Ast {
    return MakeNode(f, Ast { Label: token })
}

MakeExprStmt :: fn(f: *SourceFile, token: lex.Token, expr: *Ast) -> *Ast {
    return MakeNode(f, Ast { ExprStmt: { token: token, expr: expr } })
}

MakeAssign :: fn(f: *SourceFile, token: lex.Token, lhs, rhs: []*Ast) -> *Ast {
    return MakeNode(f, Ast { Assign: { token: token, lhs: lhs, rhs: rhs } })
}

MakeReturn :: fn(f: *SourceFile, token: lex.Token, stmts: []*Ast) -> *Ast {
    return MakeNode(f, Ast { Return: { token: token, stmts: stmts } })
}

MakeDefer :: fn(f: *SourceFile, token: lex.Token, stmt: *Ast) -> *Ast {
    return MakeNode(f, Ast { Defer: { token: token, stmt: stmt } })
}

MakeUsing :: fn(f: *SourceFile, token: lex.Token, expr: *Ast) -> *Ast {
    return MakeNode(f, Ast { Using: { token: token, expr: expr } })
}

MakeBranch :: fn(f: *SourceFile, token: lex.Token, label: *Ast) -> *Ast {
    return MakeNode(f, Ast { Branch: { token: token, label: label } })
}

MakeBlock :: fn(f: *SourceFile, begin, end: lex.Token, stmts: []*Ast) -> *Ast {
    return MakeNode(f, Ast { Block: { begin: begin, end: end, stmts: stmts } })
}

MakeIf :: fn(f: *SourceFile, token: lex.Token, cond, body, els: *Ast) -> *Ast {
    return MakeNode(f, Ast { If: { token: token, cond: cond, body: body, els: els } })
}

MakeCaseClause :: fn(f: *SourceFile, token: lex.Token, match: []*Ast, block: *Ast) -> *Ast {
    return MakeNode(f, Ast { CaseClause: { token: token, match: match, block: block } })
}

MakeSwitch :: fn(f: *SourceFile, token: lex.Token, match: *Ast, cases: []*Ast) -> *Ast {
    return MakeNode(f, Ast { Switch: { token: token, match: match, cases: cases } })
}

MakeFor :: fn(f: *SourceFile, token: lex.Token, init, cond, step, body: *Ast) -> *Ast {
    return MakeNode(f, Ast { For: { token: token, init: init, cond: cond, step: step, body: body } })
}

MakeLibrary :: fn(f: *SourceFile, token: lex.Token, path, alias: *Ast) -> *Ast {
    return MakeNode(f, Ast { Library: { token: token, path: path, alias: alias } })
}

MakeForeign :: fn(f: *SourceFile, token: lex.Token, library, decl: *Ast, linkname, callconv: []u8) -> *Ast {
    return MakeNode(f, Ast { Foreign: { token: token, library: library, decl: decl, linkname: linkname, callconv: callconv } })
}

MakeDeclaration :: fn(f: *SourceFile, token: lex.Token, names, values: []*Ast, type: *Ast, isConstant: bool) -> *Ast {
    return MakeNode(f, Ast { Declaration: { token: token, names: names, values: values, type: type, isConstant: isConstant } })
}

MakeBadDecl :: fn(f: *SourceFile, begin, end: lex.Token) -> *Ast {
    return MakeNode(f, Ast { BadDecl: { begin: begin, end: end } })
}

next0 :: fn(f: *SourceFile) -> void {
    if f.tokenIndex+1 >= f.tokens.len {
        // TODO(Brett): error
        return
    }

    f.currentToken = f.tokens[f.tokenIndex]
    f.tokenIndex += 1
}

next :: fn(f: *SourceFile) -> lex.Token {
    prev := f.currentToken
    next0(f)
    for f.currentToken.kind == lex.TokenKind.Comment {
        next0(f)
    }

    return prev
}

parseIdent :: fn(f: *SourceFile) -> *Ast {
    token := f.currentToken
    if token.kind == lex.TokenKind.Ident {
        next(f)
    } else {
        token.lit = "_"
    }

    return MakeIdent(f, token)
}

parseElement :: fn(f: *SourceFile) -> *Ast {
    if f.currentToken.kind == lex.TokenKind.Lbrace {
        return MakeKeyValue(f, f.currentToken, nil, parseCompositeLiteralBody(f, nil))
    }

    el := parseExpr(f, false)
    if f.currentToken.kind == lex.TokenKind.Colon {
        colon := next(f)
        return MakeKeyValue(f, colon, el, parseExpr(f, false))
    }

    return MakeKeyValue(f, f.currentToken, nil, el)
}

parseElementList :: fn(f: *SourceFile) -> []*Ast {
    elements := []*Ast {}
    allocator := alloc.DefaultAllocatorInit()
    alloc.ArrayInit(allocator, &elements, DefaultListLen)

    for f.currentToken.kind != lex.TokenKind.Rbrace && f.currentToken.kind != lex.TokenKind.Eof {
        alloc.Append(allocator, &elements, parseElement(f))
        if !atComma(f, lex.TokenKind.Rbrace, "composite literal")
            break

        next(f)
    }

    return elements
}

parseCompositeLiteralBody :: fn(f: *SourceFile, type: *Ast) -> *Ast {
    begin := next(f)
    elements := parseElementList(f)
    end := expect(f, lex.TokenKind.Rbrace)
    return MakeCompositeLit(f, begin, end, elements)
}

parseOperand :: fn(f: *SourceFile, allowPolyOrVariadicType: bool) -> *Ast {
    switch using f.currentToken.kind {
    case Nil:
        return MakeNilLiteral(f, next(f))
    case Ident:
        return parseIdent(f)
    case String, Int, Float:
        return MakeBasicLit(f, next(f))
    case Fn:
        token := next(f)
        type := parseFuncType(f)
        body := parseBlock(f)
        return MakeFuncLit(f, token, type, body)
    case Cast, Bitcast:
        kind := next(f)
        expect(f, lex.TokenKind.Lparen)
        explicitType := parseType(f, false, false)
        expect(f, lex.TokenKind.Rparen)
        expr := parseUnaryExpr(f, false)
        return MakeCast(f, kind, explicitType, expr)
    case Autocast:
        token := next(f)
        expr := parseUnaryExpr(f, false)
        return MakeAutocast(f, token, expr)
    case Lparen:
        return parseFuncType(f)
    }

    return parseType(f, allowPolyOrVariadicType, allowPolyOrVariadicType)
}

parseStmts :: fn(f: *SourceFile) -> []*Ast {
    stmts := []*Ast {}
    allocator := alloc.DefaultAllocatorInit()
    alloc.ArrayInit(allocator, &stmts, DefaultListLen)

    for f.currentToken.kind != lex.TokenKind.Eof {
        alloc.Append(allocator, &stmts, parseStmt(f))
    }

    return stmts
}

parseStmtList :: fn(f: *SourceFile) -> []*Ast {
    stmts: []*Ast
    allocator := alloc.DefaultAllocatorInit()
    alloc.ArrayInit(allocator, &stmts, DefaultListLen)

    using lex.TokenKind
    alloc.Append(allocator, &stmts, parseStmt(f))
    for f.currentToken.kind != Case && f.currentToken.kind != Rbrace && f.currentToken.kind != Eof {
        alloc.Append(allocator, &stmts, parseStmt(f))
    }

    return stmts
}

parseStmt :: fn(f: *SourceFile) -> *Ast {
    switch using f.currentToken.kind {
    case Ident, Int, Float, String, Fn, Lparen,
         Lbrack, Struct, Union, Enum,
         Add, Sub, Mul, And, Xor, Not, Lss:
        stmt := parseSimpleStmt(f)
        expectTerm(f)
        return stmt

    case Break, Continue, Goto, Fallthrough:
        token := next(f)
        label : *Ast = nil
        if f.currentToken.kind != Fallthrough && f.currentToken.kind == Ident {
            label = parseIdent(f)
        }

        expectTerm(f)
        return MakeBranch(f, token, label)
    case Lbrace:
        block := parseBlock(f)
        if f.currentToken.kind != Else
            expectTerm(f)
        return block
    case Rbrace:
        // NOTE: don't move the token forward
        return MakeEmpty(f, f.currentToken)
    case If:
        token := next(f)
        cond := parseExpr(f, false)
        allowTerm(f)
        body := parseStmt(f)
        els : *Ast = nil
        if f.currentToken.kind == Else {
            next(f)
            els = parseStmt(f)
        }
        return MakeIf(f, token, cond, body, els)
    case Switch:
        return parseSwitchStmt(f)
    case For:
        return parseForStmt(f)
    case Return:
        token := next(f)
        x := []*Ast {}
        if f.currentToken.kind != Semicolon && f.currentToken.kind != Rbrace
            x = parseExprList(f)
        expectTerm(f)
        return MakeReturn(f, token, x)
    case Using:
        token := next(f)
        expr := parseExpr(f, false)
        allowTerm(f)
        return MakeUsing(f, token, expr)
    case Defer:
        token := next(f)
        stmt := parseStmt(f)
        return MakeDefer(f, token, stmt)
    }

    // TODO(Brett): error and recover
    begin := next(f)
    return MakeBadStmt(f, begin, begin)
}

parseSimpleStmt :: fn(f: *SourceFile) -> *Ast {
    x := parseExprList(f)

    switch using f.currentToken.kind {
    case Assign:
        token := next(f)
        rhs := parseExprList(f)
        return MakeAssign(f, token, x, rhs)
    case AssignAdd, AssignSub, AssignMul, AssignQuo, AssignRem,
         AssignAnd, AssignOr,  AssignXor, AssignShl, AssignShr:
        token := next(f)
        rhs := parseExprList(f)
        if rhs.len > 1 || x.len > 1 {
            // TODO(Brett): error: Assignment macros only permit a single values
        }

        operation := MakeBinary(f, token, x[0], rhs[0])
        return MakeAssign(f, token, x, stmtToStmtList(operation))
    case Colon:
        token := next(f)
        if x.len == 1 && x[0].Tag == Ident && f.currentToken.kind == Semicolon && strings.Compare(f.currentToken.lit, "\n") {
            // NOTE: Ident and Label are both just tokens
            label := x[0]
            
            // FIXME(Brett): cannot, as far as I know, assign a union's tag
            //label.Tag = Label

            return label
        }

        // TODO(Brett): ensure that all elements in 'x' are Ident
        if f.currentToken.kind == Assign {
            token := next(f)
            values := parseExprList(f)
            return MakeDeclaration(f, token, x, values, nil, false)
        } else if f.currentToken.kind == Colon {
            token := next(f)
            values := parseExprList(f)
            return MakeDeclaration(f, token, x, values, nil, true)
        }

        type := parseType(f, false, false)
        switch f.currentToken.kind {
        case Assign:
            token := next(f)
            values := parseExprList(f)
            return MakeDeclaration(f, token, x, values, type, false)
        case Colon:
            token := next(f)
            values := parseExprList(f)
            return MakeDeclaration(f, token, x, values, type, true)
        case:
            return MakeDeclaration(f, token, x, []*Ast{}, type, false)
        }
    case In:
        return MakeIdentList(f, f.currentToken, x)
    }

    if x.len > 1 {
        // TODO(Brett): error: expected one expression"
    }

    return MakeExprStmt(f, x[0].Ident, x[0])
}

parseSwitchStmt :: fn(f: *SourceFile) -> *Ast {
    using lex.TokenKind

    token := expect(f, Switch)
    match : *Ast = nil
    if f.currentToken.kind != Lbrace && f.currentToken.kind != Semicolon {
        match = parseExpr(f, false)
    }

    if f.currentToken.kind == Semicolon
        next(f)

    expect(f, Lbrace)

    cases: []*Ast
    allocator := alloc.DefaultAllocatorInit()
    alloc.ArrayInit(allocator, &cases, DefaultListLen)

    alloc.Append(allocator, &cases, parseExpr(f, false))
    for f.currentToken.kind == Case {
        alloc.Append(allocator, &cases, parseCaseClause(f))
    }

    expect(f, Rbrace)
    expectTerm(f)
    return MakeSwitch(f, token, match, cases)
}

parseCaseClause :: fn(f: *SourceFile) -> *Ast {
    token := next(f)
    match := []*Ast {}
    if f.currentToken.kind != lex.TokenKind.Colon
        match = parseExprList(f)

    colon := expect(f, lex.TokenKind.Colon)
    body := parseStmtList(f)
    // TODO(Brett): fix block tokens
    block := MakeBlock(f, colon, colon, body)
    return MakeCaseClause(f, token, match, block)
}

parseForStmt :: fn(f: *SourceFile) -> *Ast {
    token := next(f)
    s1, s2, s3: *Ast = nil, nil, nil
    using lex.TokenKind

    if f.currentToken.kind == Lbrace && f.currentToken.kind != Semicolon {
        s2 = parseSimpleStmt(f)
        if s2.Tag == Ast.IdentList {
            // TODO(Brett): forin
        }
    }

    if f.currentToken.kind == Semicolon && !strings.Compare(f.currentToken.lit, "{") {
        next(f)
        s1 = s2
        s2 = nil
        if f.currentToken.kind != Semicolon
            s2 = parseSimpleStmt(f)

        expectTerm(f)
        if f.currentToken.kind != Lbrace && !(f.currentToken.kind == Semicolon && strings.Compare(f.currentToken.lit, "{")) {
            s3 = parseSimpleStmt(f)
        }
    }

    expectTerm(f)
    body := parseBlock(f)
    expectTerm(f)

    // TODO(Brett): ensure that s2 is an expression or nil
    return MakeFor(f, token, s1, s2, s3, body)
}

// TODO(Brett): struct, union, variant, enum
parseType :: fn(f: *SourceFile, allowPoly, allowVariadic: bool) -> *Ast {
    switch using f.currentToken.kind {
    case Ident:
        x := parseIdent(f)
        if f.currentToken.kind == Period {
            tok := next(f)
            return MakeSelector(f, tok, x, parseIdent(f))
        }
        return x
    case Lbrack:
        lbrack := next(f)

        isVector := false
        isImplicitlySized := false
        length: *Ast

        switch f.currentToken.kind {
        case Rbrack:
            length = nil
        case Ellipsis:
            next(f)
            length = nil
            isImplicitlySized = true
        case Ident:
            if !strings.Compare(f.currentToken.lit, "vec")
                fallthrough
            next(f)
            isVector = true
            length = parseExpr(f, false)
        case:
            length = parseExpr(f, false)
        }

        rbrack := expect(f, Rbrack)
        type := parseType(f, false, false)

        if length != nil {
            if isVector
                return MakeVectorType(f, lbrack, rbrack, length, type)
            return MakeArrayType(f, lbrack, rbrack, length, type)
        } else if isImplicitlySized {
            return MakeArrayType(f, lbrack, rbrack, nil, type)
        } else {
            return MakeSliceType(f, lbrack, rbrack, type)
        }
    case Mul:
        token := next(f)
        return MakePointerType(f, token, parseType(f, false, false))
    case Lparen:
        return parseFuncType(f)
    case Dollar:
        token := next(f)
        type := parseType(f, false, false)
        return MakePolyType(f, token, type)
    case Ellipsis:
        if !allowVariadic
            break

        ellipsis := next(f)
        return MakeVariadicType(f, ellipsis, parseType(f, true, false), false)
    case Directive:
        if !allowVariadic || !strings.Compare(f.currentToken.lit, "cvargs") {
            break
        }

        next(f)
        ellipsis := expect(f, lex.TokenKind.Ellipsis)
        return MakeVariadicType(f, ellipsis, parseType(f, true, false), true)
    }

    // TODO(Brett): error and recover
    begin := next(f)
    return MakeBadStmt(f, begin, begin)
}

parseFuncType :: fn(f: *SourceFile) -> *Ast {
    return nil
}

parseBlock :: fn(f: *SourceFile) -> *Ast {
    begin := next(f)
    stmts := []*Ast {}

    if f.currentToken.kind != lex.TokenKind.Rbrace {
        stmts = parseStmtList(f)
    }

    end := expect(f, lex.TokenKind.Rbrace)
    return MakeBlock(f, begin, end, stmts)
}

parseExpr :: fn(f: *SourceFile, allowPolyOrVariadicType: bool) -> *Ast {
    return parseBinaryExpr(f, LowestPrecedence + 1, allowPolyOrVariadicType)
}

parseExprList :: fn(f: *SourceFile) -> []*Ast {
    list: []*Ast
    allocator := alloc.DefaultAllocatorInit()
    alloc.ArrayInit(allocator, &list, DefaultListLen)

    using lex.TokenKind
    alloc.Append(allocator, &list, parseExpr(f, false))
    for f.currentToken.kind == Comma {
        next(f)
        alloc.Append(allocator, &list, parseExpr(f, false))
    }

    return list
}

parseArgumentList :: fn(f: *SourceFile) -> []*Ast, []*Ast {
    allocator := alloc.DefaultAllocatorInit()

    labels: []*Ast
    exprs:  []*Ast

    alloc.ArrayInit(allocator, &labels, DefaultListLen)
    alloc.ArrayInit(allocator, &exprs,  DefaultListLen)

    using lex.TokenKind
    for true {
        label: *Ast = nil
        expr := parseExpr(f, false)
        if expr.Tag == Ast.Ident && f.currentToken.kind == Colon {
            next(f)
            label = expr
            expr = parseExpr(f, false)
        }

        alloc.Append(allocator, &labels, label)
        alloc.Append(allocator, &exprs,  expr)

        if f.currentToken.kind != Comma
            break

        next(f)
    }

    return labels, exprs
}

parseUnaryExpr :: fn(f: *SourceFile, allowPolyOrVariadicType: bool) -> *Ast {
    switch using f.currentToken.kind {
    case Add, Sub, Not, Xor, And, Lss:
        op := next(f)
        expr := parseUnaryExpr(f, false)
        return MakeUnary(f, op, expr)
    case Mul:
        token := next(f)
        return MakePointerType(f, token, parseType(f, false, false))
    case:
        return parsePrimaryExpr(f, allowPolyOrVariadicType)
    }
}

parseBinaryExpr :: fn(f: *SourceFile, prec: u64, allowPolyOrVariadicType: bool) -> *Ast {
    lhs := parseUnaryExpr(f, allowPolyOrVariadicType)

    for true {
        op := f.currentToken
        oprec := tokenPrecedence(f)
        if oprec < prec
            return lhs

        next(f)
        rhs := parseBinaryExpr(f, oprec + 1, false)
        lhs = MakeBinary(f, op, lhs, rhs)
    }
}

parsePrimaryExpr :: fn(f: *SourceFile, allowPolyOrVariadicType: bool) -> *Ast {
    x := parseOperand(f, allowPolyOrVariadicType)

    for true {
        switch using f.currentToken.kind {
        case Period:
            token := next(f)
            x = MakeSelector(f, token, x, parseIdent(f))
        case Lbrack:
            begin := next(f)
            if f.currentToken.kind == Colon {
                next(f)
                if f.currentToken.kind == Rbrack {
                    end := next(f)
                    x = MakeSlice(f, begin, end, x, nil, nil)
                    break
                }

                hi := parseExpr(f, false)
                end := expect(f, Rbrack)
                x = MakeSlice(f, begin, end, x, nil, hi)
                break
            }

            index := parseExpr(f, false)
            if f.currentToken.kind == Colon {
                next(f)
                if f.currentToken.kind == Rbrack {
                    end := next(f)
                    x = MakeSlice(f, begin, end, x, index, nil)
                    break
                }

                hi := parseExpr(f, false)
                end := expect(f, Rbrack)
                x = MakeSlice(f, begin, end, x, index, hi)
                break
            }
            end := expect(f, Rbrack)
            x = MakeSubscript(f, begin, end, x, index)
        case Lparen:
            begin := next(f)
            labels := []*Ast {}
            exprs := []*Ast {}
            if f.currentToken.kind != Rparen {
                labels, exprs = parseArgumentList(f)
            }
            end := next(f)
            return MakeCall(f, begin, end, labels, exprs)
        case Lbrace:
            if x.Tag == Ast.FuncType {
                // TODO(Brett): error 'Unexpected '{' after function type'
                return x
            }
            return parseCompositeLiteralBody(f, x)
        case:
            return x
        }
    }

    return nil
}

stmtToStmtList :: fn(stmt: *Ast) -> []*Ast {
    stmts := []*Ast {}
    if stmt != nil {
        a := alloc.DefaultAllocatorInit()
        alloc.ArrayInit(a, &stmts, 1)
        alloc.Append(a, &stmts, stmt)
    }

    return stmts
}

tokenPrecedence :: fn(f: *SourceFile) -> u64 {
    switch using f.currentToken.kind {
    case Lor:
        return 1
    case Land:
        return 2
    case Eql, Neq, Lss, Leq, Gtr, Geq:
        return 3
    case Add, Sub, Or, Xor:
        return 4
    case Mul, Quo, Rem, Shl, Shr, And:
        return 5
    case:
        return LowestPrecedence
    }
}

tokenOperator :: fn(token: lex.Token) -> Operator {
    switch using token.kind {
    case Add, AssignAdd:
        return Operator.Add
    case Sub, AssignSub:
        return Operator.Sub
    case Mul, AssignMul:
        return Operator.Mul
    case Quo, AssignQuo:
        return Operator.Quo
    case Rem, AssignRem:
        return Operator.Rem
    case And, AssignAnd:
        return Operator.And
    case Or,  AssignOr:
        return Operator.Or
    case Xor, AssignXor:
        return Operator.Xor
    case Shl, AssignShl:
        return Operator.Shl
    case Shr, AssignShr:
        return Operator.Shr
    case:
        return Operator.Invalid
    }
}

allowTerm :: fn(f: *SourceFile) -> void {
    if f.currentToken.kind == lex.TokenKind.Semicolon
        next(f)
}

atComma :: fn(f: *SourceFile, token: lex.TokenKind, message: string) -> bool {
    if f.currentToken.kind == lex.TokenKind.Comma
        return true

    if f.currentToken.kind != token {
        if f.currentToken.kind == lex.TokenKind.Semicolon && strings.Compare(f.currentToken.lit, "\n") {
            next(f)
            if f.currentToken.kind == token return false
            // TODO(Brett): add before newline to warning
        }

        // TODO(Brett): report expected comma error
        return true
    }

    return false
}

expect :: fn(f: *SourceFile, token: lex.TokenKind) -> lex.Token {
    prev := f.currentToken
    if prev.kind != token {
        // TODO(Brett): error message
    }

    next(f)
    return prev
}

expectTerm :: fn(f: *SourceFile) -> void {
    switch using f.currentToken.kind {
        case Rparen, Rbrace: return
        case Comma:
            // TODO(Brett): error message
            fallthrough
        case Semicolon:
            next(f)
        case:
            // TODO(Brett): error message and recover
            next(f)
    }
}
