#import "lexer.kai" lex
#import "alloc.kai"
#import "ast.kai"
#import "errors.kai"
#import "strings.kai"

#import "libc.kai"

LowestPrecedence  :: 0
UnaryPrecedence   :: 7
HighestPrecedence :: 8

DefaultListLen :: 10

SourceFile :: struct {
    arena: alloc.Arena
    fullpath: string
    lexer: lex.Lexer
    tokens: []lex.Token
    tokenIndex: u64
    currentToken: lex.Token
}

SourceFileInit :: fn(file: *SourceFile, path: string) -> bool {
    lexer: lex.Lexer
    ok := lex.LexerInit(&lexer, path)
    if !ok
        return false

    allocator := alloc.DefaultAllocatorInit()
    alloc.ArrayInit(allocator, &file.tokens, lexer.data.len)

    for true {
        tok := lex.NextToken(&lexer)
        alloc.Append(allocator, &file.tokens, tok)

        libc.printf("token: \x1b[35m%s\x1b[0m, lit: \x1b[34m\"%.*s\"\x1b[0m\n".raw, lex.Describe(tok).raw, tok.lit.len, tok.lit.raw)

        if tok.kind == lex.TokenKind.Eof
            break
    }

    file.fullpath = path
    alloc.ArenaInit(&file.arena, sizeof(ast.AstNode) * lexer.data.len)

    // load the first token
    next(file)

    return true
}

MakeNode :: fn(f: *SourceFile, kind: ast.AstKind) -> *ast.AstNode {
    using alloc
    arena := &f.arena
    node := cast(*ast.AstNode)Alloc(ArenaAllocatorInit(arena), sizeof(ast.AstNode))
    node.kind = kind
    return node
}


MakeBadExpr :: fn(f: *SourceFile, begin, end: lex.Token) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.BadExpr)
    node.ast.BadExpr.begin = begin
    node.ast.BadExpr.end = end
    return node
}

MakeNilLiteral :: fn(f: *SourceFile, token: lex.Token) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.NilLiteral)
    node.ast.NilLiteral = token
    return node
}

MakeIdent :: fn(f: *SourceFile, token: lex.Token) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Ident)
    node.ast.Ident = token
    return node
}

MakeEllipsis :: fn(f: *SourceFile, expr: *ast.AstNode, token: lex.Token) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Ellipsis)
    node.ast.Ellipsis.expr = expr
    node.ast.Ellipsis.token = token
    return node
}

MakeBasicLit :: fn(f: *SourceFile, token: lex.Token) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.BasicLit)
    node.ast.BasicLit = token
    return node
}

MakeFuncLit :: fn(f: *SourceFile, token: lex.Token, type, body: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.FuncLit)
    node.ast.FuncLit.token = token
    node.ast.FuncLit.type = type
    node.ast.FuncLit.body = body
    return node
}

MakeCompositeLit :: fn(f: *SourceFile, begin, end: lex.Token, elements: []*ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.CompositeLit)
    node.ast.CompositeLit.begin = begin
    node.ast.CompositeLit.end = end
    node.ast.CompositeLit.elements = elements
    return node
}

MakeParen :: fn(f: *SourceFile, begin, end: lex.Token, expr: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Paren)
    node.ast.Paren.begin = begin
    node.ast.Paren.end = end
    node.ast.Paren.expr = expr
    return node
}

MakeSelector :: fn(f: *SourceFile, token: lex.Token, rec, sel: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Selector)
    node.ast.Selector.token = token
    node.ast.Selector.rec = rec
    node.ast.Selector.sel = sel
    return node
}

MakeSubscript :: fn(f: *SourceFile, begin, end: lex.Token, rec, index: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Subscript)
    node.ast.Subscript.begin = begin
    node.ast.Subscript.end = end
    node.ast.Subscript.rec = rec
    node.ast.Subscript.index = index
    return node
}

MakeSlice :: fn(f: *SourceFile, begin, end: lex.Token, expr, hi, lo: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Slice)
    node.ast.Slice.begin = begin
    node.ast.Slice.end = end
    node.ast.Slice.expr = expr
    node.ast.Slice.hi = hi
    node.ast.Slice.lo = lo
    return node
}

MakeAutocast :: fn(f: *SourceFile, token: lex.Token, expr: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Autocast)
    node.ast.Autocast.token = token
    node.ast.Autocast.expr = expr
    return node
}

MakeCast :: fn(f: *SourceFile, kind: lex.Token, type, expr: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Cast)
    node.ast.Cast.kind = kind
    node.ast.Cast.type = type
    node.ast.Cast.expr = expr
    return node
}

MakeCall :: fn(f: *SourceFile, begin, end: lex.Token, labels, args: []*ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Call)
    node.ast.Call.begin = begin
    node.ast.Call.end = end
    node.ast.Call.labels = labels
    node.ast.Call.args = args
    return node
}

MakeUnary :: fn(f: *SourceFile, op: lex.Token, element: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Unary)
    node.ast.Unary.op = op
    node.ast.Unary.element = element
    return node
}

MakeBinary :: fn(f: *SourceFile, op: lex.Token, lhs, rhs: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Binary)
    node.ast.Binary.op = op
    node.ast.Binary.lhs = lhs
    node.ast.Binary.rhs = rhs
    return node
}

MakeTernary :: fn(f: *SourceFile, qmark, colon: lex.Token, cond, then, els: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Ternary)
    node.ast.Ternary.qmark = qmark
    node.ast.Ternary.colon = colon
    node.ast.Ternary.cond = cond
    node.ast.Ternary.then = then
    node.ast.Ternary.els = els
    return node
}

MakeKeyValue :: fn(f: *SourceFile, token: lex.Token, key, value: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.KeyValue)
    node.ast.KeyValue.token = token
    node.ast.KeyValue.key = key
    node.ast.KeyValue.value = value
    return node
}

MakePointerType :: fn(f: *SourceFile, token: lex.Token, type: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.PointerType)
    node.ast.PointerType.token = token
    node.ast.PointerType.type = type
    return node
}

MakeArrayType :: fn(f: *SourceFile, begin, end: lex.Token, length, type: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.ArrayType)
    node.ast.ArrayType.begin = begin
    node.ast.ArrayType.end = end
    node.ast.ArrayType.length = length
    node.ast.ArrayType.type = type
    return node
}

MakeSliceType :: fn(f: *SourceFile, begin, end: lex.Token, type: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.SliceType)
    node.ast.SliceType.begin = begin
    node.ast.SliceType.end = end
    node.ast.SliceType.type = type
    return node
}

MakeVectorType :: fn(f: *SourceFile, begin, end: lex.Token, size, type: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.VectorType)
    node.ast.VectorType.begin = begin
    node.ast.VectorType.end = end
    node.ast.VectorType.size = size
    node.ast.VectorType.type = type
    return node
}

MakePolyType :: fn(f: *SourceFile, token: lex.Token, type: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.PolyType)
    node.ast.PolyType.token = token
    node.ast.PolyType.type = type
    return node
}

MakeVariadicType :: fn(f: *SourceFile, token: lex.Token, type: *ast.AstNode, isCVargs: bool) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.VariadicType)
    node.ast.VariadicType.token = token
    node.ast.VariadicType.type = type
    node.ast.VariadicType.isCVargs = isCVargs
    return node
}

MakeBadStmt :: fn(f: *SourceFile, begin, end: lex.Token) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.BadStmt)
    node.ast.BadStmt.begin = begin
    node.ast.BadStmt.end = end
    return node
}

MakeEmpty :: fn(f: *SourceFile, token: lex.Token) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Empty)
    node.ast.Empty = token
    return node
}

MakeReturn :: fn(f: *SourceFile, token: lex.Token, stmts: []*ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Return)
    node.ast.Return.token = token
    node.ast.Return.stmts = stmts
    return node
}

MakeDefer :: fn(f: *SourceFile, token: lex.Token, stmt: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Defer)
    node.ast.Defer.token = token
    node.ast.Defer.stmt = stmt
    return node
}

MakeUsing :: fn(f: *SourceFile, token: lex.Token, expr: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Using)
    node.ast.Using.token = token
    node.ast.Using.expr = expr
    return node
}

MakeBranch :: fn(f: *SourceFile, token: lex.Token, label: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Branch)
    node.ast.Branch.token = token
    node.ast.Branch.label = label
    return node
}

MakeBlock :: fn(f: *SourceFile, begin, end: lex.Token, stmts: []*ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Block)
    node.ast.Block.begin = begin
    node.ast.Block.end = end
    node.ast.Block.stmts = stmts
    return node
}

MakeIf :: fn(f: *SourceFile, token: lex.Token, cond, body, els: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.If)
    node.ast.If.token = token
    node.ast.If.cond = cond
    node.ast.If.body = body
    node.ast.If.els = els
    return node
}

MakeFor :: fn(f: *SourceFile, token: lex.Token, init, cond, step, body: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.For)
    node.ast.For.token = token
    node.ast.For.init = init
    node.ast.For.cond = cond
    node.ast.For.step = step
    node.ast.For.body = body
    return node
}

MakeLibrary :: fn(f: *SourceFile, token: lex.Token, path, alias: *ast.AstNode) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Library)
    node.ast.Library.token = token
    node.ast.Library.path = path
    node.ast.Library.alias = alias
    return node
}

MakeForeign :: fn(f: *SourceFile, token: lex.Token, library, decl: *ast.AstNode, linkname, callconv: []u8) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.Foreign)
    node.ast.Foreign.token = token
    node.ast.Foreign.library = library
    node.ast.Foreign.decl = decl
    node.ast.Foreign.linkname = linkname
    node.ast.Foreign.callconv = callconv
    return node
}

MakeBadDecl :: fn(f: *SourceFile, begin, end: lex.Token) -> *ast.AstNode {
    node := MakeNode(f, ast.AstKind.BadDecl)
    node.ast.BadDecl.begin = begin
    node.ast.BadDecl.end = end
    return node
}

next0 :: fn(f: *SourceFile) -> void {
    if f.tokenIndex+1 >= f.tokens.len {
        // TODO(Brett): error
        return
    }

    f.currentToken = f.tokens[f.tokenIndex]
    f.tokenIndex += 1
}

next :: fn(f: *SourceFile) -> lex.Token {
    prev := f.currentToken
    next0(f)
    for f.currentToken.kind == lex.TokenKind.Comment {
        next0(f)
    }

    return prev
}

parseIdent :: fn(f: *SourceFile) -> *ast.AstNode {
    token := f.currentToken
    if token.kind == lex.TokenKind.Ident {
        next(f)
    } else {
        token.lit = "_"
    }

    return MakeIdent(f, token)
}

parseElement :: fn(f: *SourceFile) -> *ast.AstNode {
    if f.currentToken.kind == lex.TokenKind.Lbrace {
        return MakeKeyValue(f, f.currentToken, nil, parseCompositeLiteralBody(f, nil))
    }

    el := parseExpr(f, false)
    if f.currentToken.kind == lex.TokenKind.Colon {
        colon := next(f)
        return MakeKeyValue(f, colon, el, parseExpr(f, false))
    }

    return MakeKeyValue(f, f.currentToken, nil, el)
}

parseElementList :: fn(f: *SourceFile) -> []*ast.AstNode {
    elements := []*ast.AstNode {}
    allocator := alloc.DefaultAllocatorInit()
    alloc.ArrayInit(allocator, &elements, DefaultListLen)

    for f.currentToken.kind != lex.TokenKind.Rbrace && f.currentToken.kind != lex.TokenKind.Eof {
        alloc.Append(allocator, &elements, parseElement(f))
        if !atComma(f, lex.TokenKind.Rbrace, "composite literal")
            break

        next(f)
    }

    return elements
}

parseCompositeLiteralBody :: fn(f: *SourceFile, type: *ast.AstNode) -> *ast.AstNode {
    begin := next(f)
    elements := parseElementList(f)
    end := expect(f, lex.TokenKind.Rbrace)
    return MakeCompositeLit(f, begin, end, elements)
}

parseOperand :: fn(f: *SourceFile, allowPolyOrVariadicType: bool) -> *ast.AstNode {
    using lex.TokenKind
    switch f.currentToken.kind {
    case Nil:
        return MakeNilLiteral(f, next(f))
    case Ident:
        return parseIdent(f)
    case String, Int, Float:
        return MakeBasicLit(f, next(f))
    case Fn:
        token := next(f)
        type := parseFuncType(f, false)
        body := parseBlock(f)
        return MakeFuncLit(f, token, type, body)
    case Cast, Bitcast:
        kind := next(f)
        expect(f, lex.TokenKind.Lparen)
        explicitType := parseType(f, false, false)
        expect(f, lex.TokenKind.Rparen)
        expr := parseUnaryExpr(f, false)
        return MakeCast(f, kind, explicitType, expr)
    case Autocast:
        token := next(f)
        expr := parseUnaryExpr(f, false)
        return MakeAutocast(f, token, expr)
    case Lparen:
        return parseFuncType(f, true)
    }

    return nil
}

parseStmts :: fn(f: *SourceFile) -> []*ast.AstNode {
    stmts := []*ast.AstNode {}
    allocator := alloc.DefaultAllocatorInit()
    alloc.ArrayInit(allocator, &stmts, DefaultListLen)

    for f.currentToken.kind != lex.TokenKind.Eof {
        alloc.Append(allocator, &stmts, parseStmt(f))
    }

    return stmts
}

parseStmtList :: fn(f: *SourceFile) -> []*ast.AstNode {
    stmts: []*ast.AstNode
    allocator := alloc.DefaultAllocatorInit()
    alloc.ArrayInit(allocator, &stmts, DefaultListLen)

    using lex.TokenKind
    alloc.Append(allocator, &stmts, parseStmt(f))
    for f.currentToken.kind != Case && f.currentToken.kind != Rbrace && f.currentToken.kind != Eof {
        alloc.Append(allocator, &stmts, parseStmt(f))
    }

    return stmts
}

parseStmt :: fn(f: *SourceFile) -> *ast.AstNode {
    using lex.TokenKind
    switch f.currentToken.kind {
    case Ident, Int, Float, String, Fn, Lparen,
         Lbrack, Struct, Union, Enum,
         Add, Sub, Mul, And, Xor, Not, Lss:
        stmt := parseSimpleStmt(f)
        expectTerm(f)
        return stmt

    case Break, Continue, Goto, Fallthrough:
        token := next(f)
        label : *ast.AstNode = nil
        if f.currentToken.kind != Fallthrough && f.currentToken.kind == Ident {
            label = parseIdent(f)
        }

        expectTerm(f)
        return MakeBranch(f, token, label)
    case Lbrace:
        block := parseBlock(f)
        if f.currentToken.kind != Else
            expectTerm(f)
        return block
    case Rbrace:
        // NOTE: don't move the token forward
        return MakeEmpty(f, f.currentToken)
    case If:
        token := next(f)
        cond := parseExpr(f, false)
        allowTerm(f)
        body := parseStmt(f)
        els : *ast.AstNode = nil
        if f.currentToken.kind == Else {
            next(f)
            els = parseStmt(f)
        }
        return MakeIf(f, token, cond, body, els)

    // TODO(Brett): Switch and directive cases

    case Return:
        token := next(f)
        x := []*ast.AstNode {}
        if f.currentToken.kind != Semicolon && f.currentToken.kind != Rbrace
            x = parseExprList(f)
        expectTerm(f)
        return MakeReturn(f, token, x)
    case Using:
        token := next(f)
        expr := parseExpr(f, false)
        allowTerm(f)
        return MakeUsing(f, token, expr)
    case Defer:
        token := next(f)
        stmt := parseStmt(f)
        return MakeDefer(f, token, stmt)
    }

    // TODO(Brett): error and recover
    begin := next(f)
    return MakeBadStmt(f, begin, begin)
}

parseSimpleStmt :: fn(f: *SourceFile) -> *ast.AstNode {
    return nil
}

parseType :: fn(f: *SourceFile, allowPoly, allowVariadic: bool) -> *ast.AstNode {
    using lex.TokenKind
    switch f.currentToken.kind {
    case Ident:
        x := parseIdent(f)
        if f.currentToken.kind == Period {
            tok := next(f)
            return MakeSelector(f, tok, x, parseIdent(f))
        }
        return x
    case Lbrack:
        lbrack := next(f)

        isVector := false
        isImplicitlySized := false
        length: *ast.AstNode

        switch f.currentToken.kind {
        case Rbrack:
            length = nil
        case Ellipsis:
            next(f)
            length = nil
            isImplicitlySized = true
        case Ident:
            if !strings.Compare(f.currentToken.lit, "vec")
                fallthrough
            next(f)
            isVector = true
            length = parseExpr(f, false)
        case:
            length = parseExpr(f, false)
        }

        rbrack := expect(f, Rbrack)
        type := parseType(f, false, false)

        if length != nil {
            if isVector
                return MakeVectorType(f, lbrack, rbrack, length, type)
            return MakeArrayType(f, lbrack, rbrack, length, type)
        } else if isImplicitlySized {
            return MakeArrayType(f, lbrack, rbrack, nil, type)
        } else {
            return MakeSliceType(f, lbrack, rbrack, type)
        }
    case Mul:
        token := next(f)
        return MakePointerType(f, token, parseType(f, false, false))
    case Dollar:
        token := next(f)
        type := parseType(f, false, false)
        return MakePolyType(f, token, type)
    case Ellipsis:
        if !allowVariadic
            break

        ellipsis := next(f)
        return MakeVariadicType(f, ellipsis, parseType(f, true, false), false)
    case Directive:
        if !allowVariadic || !strings.Compare(f.currentToken.lit, "cvargs") {
            break
        }

        next(f)
        ellipsis := expect(f, lex.TokenKind.Ellipsis)
        return MakeVariadicType(f, ellipsis, parseType(f, true, false), true)
    }

    // TODO(Brett): error and recover
    begin := next(f)
    return MakeBadStmt(f, begin, begin)
}

parseFuncType :: fn(f: *SourceFile, allowParenthesizedExpr: bool) -> *ast.AstNode {
    return nil
}

parseBlock :: fn(f: *SourceFile) -> *ast.AstNode {
    begin := next(f)
    stmts := []*ast.AstNode {}

    if f.currentToken.kind != lex.TokenKind.Rbrace {
        stmts = parseStmtList(f)
    }

    end := expect(f, lex.TokenKind.Rbrace)
    return MakeBlock(f, begin, end, stmts)
}

parseExpr :: fn(f: *SourceFile, allowPolyOrVariadicType: bool) -> *ast.AstNode {
    return parseBinaryExpr(f, LowestPrecedence + 1, allowPolyOrVariadicType)
}

parseExprList :: fn(f: *SourceFile) -> []*ast.AstNode {
    list: []*ast.AstNode
    allocator := alloc.DefaultAllocatorInit()
    alloc.ArrayInit(allocator, &list, DefaultListLen)

    using lex.TokenKind
    alloc.Append(allocator, &list, parseExpr(f, false))
    for f.currentToken.kind == Comma{
        next(f)
        alloc.Append(allocator, &list, parseExpr(f, false))
    }

    return list
}

parseArgumentList :: fn(f: *SourceFile) -> []*ast.AstNode, []*ast.AstNode {
    allocator := alloc.DefaultAllocatorInit()

    labels: []*ast.AstNode
    exprs:  []*ast.AstNode

    alloc.ArrayInit(allocator, &labels, DefaultListLen)
    alloc.ArrayInit(allocator, &exprs,  DefaultListLen)

    using lex.TokenKind
    for true {
        label: *ast.AstNode = nil
        expr := parseExpr(f, false)
        if expr.kind == ast.AstKind.Ident && f.currentToken.kind == Colon {
            next(f)
            label = expr
            expr = parseExpr(f, false)
        }

        alloc.Append(allocator, &labels, label)
        alloc.Append(allocator, &exprs,  expr)

        if f.currentToken.kind != Comma
            break

        next(f)
    }

    return labels, exprs
}

parseUnaryExpr :: fn(f: *SourceFile, allowPolyOrVariadicType: bool) -> *ast.AstNode {
    using lex.TokenKind
    switch f.currentToken.kind {
    case Add, Sub, Not, Xor, And, Lss:
        op := next(f)
        expr := parseUnaryExpr(f, false)
        return MakeUnary(f, op, expr)
    case Mul:
        token := next(f)
        return MakePointerType(f, token, parseType(f, false, false))
    case:
        return parsePrimaryExpr(f, allowPolyOrVariadicType)
    }
}

parseBinaryExpr :: fn(f: *SourceFile, prec: u64, allowPolyOrVariadicType: bool) -> *ast.AstNode {
    lhs := parseUnaryExpr(f, allowPolyOrVariadicType)

    for true {
        op := f.currentToken
        oprec := tokenPrecedence(f)
        if oprec < prec
            return lhs

        next(f)
        rhs := parseBinaryExpr(f, oprec + 1, false)
        lhs = MakeBinary(f, op, lhs, rhs)
    }
}

parsePrimaryExpr :: fn(f: *SourceFile, allowPolyOrVariadicType: bool) -> *ast.AstNode {
    x := parseOperand(f, allowPolyOrVariadicType)

    using lex.TokenKind
    for true {
        switch f.currentToken.kind {
        case Period:
            token := next(f)
            x = MakeSelector(f, token, x, parseIdent(f))
        case Lbrack:
            begin := next(f)
            if f.currentToken.kind == Colon {
                next(f)
                if f.currentToken.kind == Rbrack {
                    end := next(f)
                    x = MakeSlice(f, begin, end, x, nil, nil)
                    break
                }

                hi := parseExpr(f, false)
                end := expect(f, Rbrack)
                x = MakeSlice(f, begin, end, x, nil, hi)
                break
            }

            index := parseExpr(f, false)
            if f.currentToken.kind == Colon {
                next(f)
                if f.currentToken.kind == Rbrack {
                    end := next(f)
                    x = MakeSlice(f, begin, end, x, index, nil)
                    break
                }

                hi := parseExpr(f, false)
                end := expect(f, Rbrack)
                x = MakeSlice(f, begin, end, x, index, hi)
                break
            }
            end := expect(f, Rbrack)
            x = MakeSubscript(f, begin, end, x, index)
        case Lparen:
            begin := next(f)
            labels := []*ast.AstNode {}
            exprs := []*ast.AstNode {}
            if f.currentToken.kind != Rparen {
                labels, exprs = parseArgumentList(f)
            }
            end := next(f)
            return MakeCall(f, begin, end, labels, exprs)
        case Lbrace:
            if x.kind == ast.AstKind.FuncType {
                // TODO(Brett): error 'Unexpected '{' after function type'
                return x
            }
            return parseCompositeLiteralBody(f, x)
        case:
            return x
        }
    }

    return nil
}

tokenPrecedence :: fn(f: *SourceFile) -> u64 {
    using lex.TokenKind
    switch f.currentToken.kind {
    case Lor:
        return 1
    case Land:
        return 2
    case Eql, Neq, Lss, Leq, Gtr, Geq:
        return 3
    case Add, Sub, Or, Xor:
        return 4
    case Mul, Quo, Rem, Shl, Shr, And:
        return 5
    case:
        return LowestPrecedence
    }
}

allowTerm :: fn(f: *SourceFile) -> void {
    if f.currentToken.kind == lex.TokenKind.Semicolon
        next(f)
}

atComma :: fn(f: *SourceFile, token: lex.TokenKind, message: string) -> bool {
    if f.currentToken.kind == lex.TokenKind.Comma
        return true

    if f.currentToken.kind != token {
        if f.currentToken.kind == lex.TokenKind.Semicolon && strings.Compare(f.currentToken.lit, "\n") {
            next(f)
            if f.currentToken.kind == token return false
            // TODO(Brett): add before newline to warning
        }

        // TODO(Brett): report expected comma error
        return true
    }

    return false
}

expect :: fn(f: *SourceFile, token: lex.TokenKind) -> lex.Token {
    prev := f.currentToken
    if prev.kind != token {
        // TODO(Brett): error message
    }

    next(f)
    return prev
}

expectTerm :: fn(f: *SourceFile) -> void {
    using lex.TokenKind
    switch f.currentToken.kind {
        case Rparen, Rbrace: return
        case Comma:
            // TODO(Brett): error message
            fallthrough
        case Semicolon:
            next(f)
        case:
            // TODO(Brett): error message and recover
            next(f)
    }
}
