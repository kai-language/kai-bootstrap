#import "lexer.kai" lex
#import "alloc.kai"
#import "ast.kai"
#import "errors.kai"

SourceFile :: struct {
    arena: alloc.Arena
    fullpath: string
    lexer: lex.Lexer
    tokens: []lex.Token
}

SourceFileInit :: fn(file: *SourceFile, path: string) -> bool {
    lexer: lex.Lexer
    ok := lex.LexerInit(&lexer, path)
    if !ok
        return false

    allocator := alloc.DefaultAllocatorInit()
    alloc.ArrayInit(allocator, &file.tokens, lexer.data.len)

    for true {
        tok := lex.NextToken(&lexer)
        alloc.Append(allocator, &file.tokens, tok)
        /*libc.printf("token: \x1b[35m%s\x1b[0m, lit: \x1b[34m\"".raw, lex.Describe(tok).raw)
        for char in tok.str {
            libc.printf("%c".raw, char)
        }
        libc.printf("\"\x1b[0m\n".raw)
        */
        if tok.kind == lex.TokenKind.Eof
            break
    }

    node: ast.AstNode
    node.kind = ast.AstKind.Ellipsis
    node.ast.Ellipsis.expr = nil;

    file.fullpath = path
    alloc.ArenaInit(&file.arena, sizeof(ast.AstNode) * lexer.data.len)

    return true
}
